<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[A Write Protect Blog]]></title>
  <link href="http://cnut-wp.github.com/atom.xml" rel="self"/>
  <link href="http://cnut-wp.github.com/"/>
  <updated>2013-12-16T22:03:08+08:00</updated>
  <id>http://cnut-wp.github.com/</id>
  <author>
    <name><![CDATA[Peng Wang]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[something about lock]]></title>
    <link href="http://cnut-wp.github.com/blog/2013/12/15/something-about-lock/"/>
    <updated>2013-12-15T21:27:00+08:00</updated>
    <id>http://cnut-wp.github.com/blog/2013/12/15/something-about-lock</id>
    <content type="html"><![CDATA[<p>老早就想梳理一下关于 Hardware &amp;&amp; Lock 的知识，一直没有完成，比较惭愧。</p>

<p>这两方面的知识都比较多，现在本人还处于学习阶段，望指教。</p>

<p>最近我们组学习 SOSP13&#8217; Paper Everything You Always Wanted to Know about Synchronization but Were Afraid to Ask,
这篇 paper 主要讲 Hardware 对 Scalability 的影响 (文章涉及四个厂商的硬件，很好地总结了它们的特点，值得学习), 同时涉及到一些 Lock 的 Scalability 分析。</p>

<p>首先说一下硬件情况。
<img src="http://cnut-wp.github.com/images/hardware-perf.png" alt="enqueue" /></p>

<p>本文主要讲一下几种锁 Lock 以及它们的优化原因。</p>

<p>基于 Test_And_Set 最简单的 Spin Lock ：</p>

<pre><code>type lock = (unlocked, locked)

procedure acquire_lock (L : ^lock)
    delay : integer := 1
    while test_and_set (L) = locked     // returns old value
        pause (delay)                   // consume this many units of time, back-off
        delay := delay * 2

procedure release_lock (L : ^lock)
    lock^ := unlocked
</code></pre>

<p>这种实现的 Spin Lock, 已经加入了 back-off.</p>

<p>Back-off  是为了干什么？
几个例子，如果今天早上外面公里上出现堵车情况，你最好不要马上出门。因为更多的人出门，只会造成公路更加拥挤。
既然说起来堵车这个比喻，我就在细说一下吧。
出现堵车的根本原因是，现在公路的运输能力不够。
在不改变公路的情况下，我们能做的就是充分把公路的运输能力挖掘出来。
最理想的情况就是，知道每个人要从哪里到哪里，然后安排好他们的出门时间，让整个公路通畅运行没有堵的情况出现，这样才能保证公路时刻都在以最大的效率运输车辆。
前面的 back-off 想做的就是这个。</p>

<p>具体到运行在某个硬件上的锁是这样的：在多核环境下，Lock 不管怎么实现，最终对归结为对某个内存的操作，由于多个核都可以看到这个内存，需要通过 Cache Coherence 协议保证对该变量访问和操作的一致性。
Cache Coherence 协议简单来说就是不同的核(可以这样理解，真正的硬件可能是 memory node controler)通过一系列的消息来保证不同核看到的数据 (cache line ) 是一致的。
有不同的 Cache Coherence 协议，一般我们都会在教科书上学习到基于四种状态 Modified Exclusive Shared Invalid (MESI) 的 Cache Coherence 协议。</p>

<p>在 Intel 机器上可能还会有一个 Forward 的状态,论文中说是为了</p>

<pre><code>This state is a special form of the shared state and indicates
the only cache that will respond to a load request for that line (thus reducing bandwidth usage)。
</code></pre>

<p>AMD 多了个 Owner 的状态，论文中说是为了：</p>

<pre><code>The Opteron uses the MOESI protocol for cache coherence.
The ‘O’ stands for the owned state, 
which indicates that this cache line has been modified (by the owner) 
but there might be more shared copies on other cores.
This state allows a core to load a modified line of another core
without the need to invalidate the modified line.
The modified cache line simply changes to owned and the new core receives the line in shared state.
</code></pre>

<p>一个简单的场景。
许多核读了一个没有改变过的变量，这样每个核的 cache 中都会有一个处于 shared 状态的该变量。
而之后有个核 (例如 Core 1) 写了这个变量，它需要保证其他核看到正确的结果，由于之前其他核上的 cache 中已经有处于 share 状态的该变量，core 1 在完成写该变量的过程中需要 invalidate 其他核的该条 cache line。</p>

<p>如果明白上面场景，就可以明白为什么需要引入 back-off (即在拿不到锁后等一段时间)，这样做的目的是：如果你拿锁拿不到，证明有竞争，如果你这个时候再去试着拿锁，势必带来更多的 cache coherence message,
在 contention 十分重的情况下(极端情况就是每个核都在不断地操作这个变量)，这些 cache coherence message 会引起严重的性能问题。
(Non-scalable locks are dangerous 论文里面对这个问题做了很好的分析)。
在这种情况下，还不如你稍微等一下，在别人用完锁后你再去拿锁可以避免竞争，从而带来性能提升。</p>

<p>上面实现的 Spin Lock 最大的问题就是会有饿死的情况。(某个核不幸永远拿不到锁)</p>

<p>Ticket Spin Lock 可以保证公平:</p>

<pre><code>type lock = record
    next_ticket : unsigned integer := 0
    now_serving : unsigned integer := 0

procedure acquire_lock (L : ^lock)
    my_ticket : unsigned integer := fetch_and_increment (&amp;L-&gt;next_ticket)  
    // returns old value; arithmetic overflow is harmless

    loop
        pause (my_ticket - L-&gt;now_serving)
            // consume this many units of time
            // on most machines, subtraction works correctly despite overflow
        if L-&gt;now_serving = my_ticket
            return

procedure release_lock (L : ^lock)
    L-&gt;now_serving := L-&gt;now_serving + 1
</code></pre>

<p>Ticket Spin Lock 很好地解决了饿死的问题。(每个人先去领个号，按号拿锁。一个人用完锁后通过共享变量通知下一个人)</p>

<p>此外，Back-off 在 Ticket Spin Lock 中可以更优雅的实现。</p>

<p>但是上面两篇文章都提到了 Spin Lock Scalability 不好。
原因是他们还是有共享变量 (那不到锁的人都会 spinning 在 now_serving，释放锁的开销比较大)。在核多的情况，会带来性能问题。</p>

<p>最好能够让每个核 spinning 在各自的 local 变量上， MCS Lock 做到了这一点。</p>

<pre><code>type qnode = record
    next : ^qnode
    locked : Boolean

type lock = ^qnode      // initialized to nil

// parameter I, below, points to a qnode record allocated
// (in an enclosing scope) in shared memory locally-accessible
// to the invoking processor

procedure acquire_lock (L : ^lock, I : ^qnode)
    I-&gt;next := nil
    predecessor : ^qnode := fetch_and_store (L, I)
    if predecessor != nil      // queue was non-empty
        I-&gt;locked := true
        predecessor-&gt;next := I
        repeat while I-&gt;locked              // spin

procedure release_lock (L : ^lock, I: ^qnode)
    if I-&gt;next = nil        // no known successor
        if compare_and_store (L, I, nil)
            return
            // compare_and_store returns true iff it stored
        repeat while I-&gt;next = nil          // spin
    I-&gt;next-&gt;locked := false
</code></pre>

<p>在上面实现的 MCS Lock 中，各个线程只会 spin 在自己的 local 变量  I:qnode  上。释放锁的人理想情况下只会给一个人发 invalidate 消息。</p>

<p>如果考虑到 NUNA 的特性，还可以继续提高 Lock 的 throughput. (同一个 NUMA Node 访问会比跨 NUMA Node 的访问快， 于是我们可以让锁具有偏向性，让位于一个 NUMA Node 上的 Core 更容易拿到锁)</p>

<p><img src="http://cnut-wp.github.com/images/atomic-throughput.png" alt="enqueue" /></p>

<p><img src="http://cnut-wp.github.com/images/lock-throughput.png" alt="enqueue" /></p>

<p>其实我们可以发现单个 Core 的 throughput 远大于多个 Core 的 throughput。原因是什么？ Contention 太中， cache coherence message 太多。</p>

<p>所以如果碰到性能问题，首先想到的不是去优化锁的性能，而是减少自身程序的 contention。
如果真的不行，在去考虑各种锁的实现，再不行的话，可以考虑采取其他同步机制了 RCU, Transaction Memory, Message Passing.</p>

<p>参考文档：</p>

<ul>
<li>Everything You Always Wanted to Know about Synchronization but Were Afraid to Ask</li>
<li>Non-scalable locks are dangerous</li>
<li><a href="http://www.cs.rochester.edu/research/synchronization/pseudocode/ss.html">http://www.cs.rochester.edu/research/synchronization/pseudocode/ss.html</a></li>
<li><a href="http://www.cs.tau.ac.il/~afek/Spin%20Locks%20and%20Contention.ppt">Spinlock and Contention</a> <a href="http://cnut-wp.github.com/material/Spin%20Locks%20and%20Contention.ppt">Local Copy</a></li>
</ul>


<p>其中测试结果全部来自第一篇文章。
伪代码全部来自第三个参考文献。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Top of Tides]]></title>
    <link href="http://cnut-wp.github.com/blog/2013/07/19/On-Top-of-Tides/"/>
    <updated>2013-07-19T18:00:00+08:00</updated>
    <id>http://cnut-wp.github.com/blog/2013/07/19/On-Top-of-Tides</id>
    <content type="html"><![CDATA[<p>最近在看《浪潮之巅》，感觉这是一本很不错的书，读这本书的时候让自己的计算机行业有了更多的理解。在这里推荐一下。</p>

<blockquote><p>近一百多年来，总有一些公司很幸运地、有意识或无意识地站在技术革命的浪尖之上。在这十几年间，它们代表着科技的浪潮，直到下一波浪潮的来临。</p>

<p>对于一个弄潮的年轻人来讲，最幸运的，莫过于赶上一波大潮</p></blockquote>

<p>上面是书开头的一段话。《浪潮之巅》书中介绍了IT行业各个时期的弄潮儿，也分析了IT行业的各种特点。出于了解历史或者让自己对于IT行业更加了解，这本书都值得一读。</p>

<p>计算机工业的生态链三定律：</p>

<ul>
<li>摩尔定律:当价格不变时，集成电路上可容纳的晶体管数目，约每隔18个月便会增加一倍，性能也将提升一倍。</li>
<li>安迪-比尔定律: What Andy gives, Bill takes away。</li>
<li>反摩尔定律：一个IT公司如果今天和18个月前卖掉同样多的、同样的产品，它的营业额就要降一半。</li>
</ul>


<p>摩尔定律，几乎每个IT行业人员都知道。有一种说法是这样的：IT行业为什么能以这么快的速度发展，并且持续这么长时间？因为IT行业的从事者能够不断用新的软硬件去设计新的软硬件，从而能不断保持以指数的速度发展。</p>

<p>安迪-比尔定律，这是我们不断更新我们 PC 的原因。Andy 是 Intel 的老总，Bill 则是 Microsoft 的老总。Microsoft 不断推出新的更强大的系统，但是这些系统只能在更新的硬件上才能跑的起来，为了使用更友好更流畅的系统，没有办法我们只能去更新系统。这也决定了 Microsoft 在 PC 时代位于计算机工业的上游，而生产硬件的公司则位于整个生态的中下游。一个例子就是：由于 Vista 的延期推出，各大 PC 硬件厂商相应的销售受到了很大的影响。</p>

<p>反摩尔定律则对应 IT 公司是致命的。SUN 曾经是打败包括 IBM 在内所有工作站和小型机公司的伟大公司，市值一度超过2000亿美元，公司中也不乏能人。但是它只想通过卖它的硬件赚钱，受反摩尔定律的影响，自己又没有找到新的盈利方式（它毕竟与那么多牛逼的技术，例如风靡全球但是不赚钱的 JAVA），最终被 ORACLE 以74亿美元收购。反摩尔定律要求 IT 公司不断地创新，否则很可能马上走向衰败。反摩尔定律，现在看主要是影响那些以硬件为主的公司，而以软件服务为主的公司，影响着没有那么大，例如现在的 IBM。</p>

<p>书中把许多公司的命运归结于公司的基因，Apple 的基因是创新，所以它能在许多年低谷后重新引领时代，而 SUN 虽然它也有许多能人，但是由于它没有把技术优势转化为利润的基因，而最终没落。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[lock free queue]]></title>
    <link href="http://cnut-wp.github.com/blog/2013/05/01/lock-free-queue/"/>
    <updated>2013-05-01T15:08:00+08:00</updated>
    <id>http://cnut-wp.github.com/blog/2013/05/01/lock-free-queue</id>
    <content type="html"><![CDATA[<p>最近，看了一些关于 Lock-Free Queue 的 Paper，感觉挺有意思的。
为什么产生 Lock-Free 的数据结构？原因是这样的，在 Concurrent Programming 中，由于下面的 OS是抢占调度的，完全有可能出现这样一种情况：持有锁的线程被调度走，而等待锁的线程却被调度上 CPU,这样带来的一个后果就是：正在运行的线程由于没有锁而无法推进，它必须得等到持有锁的线程重新被调度上CPU并释放释放锁后才能继续运行。
为了解决这个问题，许多研究工作者就发明了 non-blocking 的数据结构（又叫： Lock-Free Data Structure）。</p>

<pre><code>An implementation of a data structure is nonblocking (also known as lock-free) if it
guarantees that at least one process of those trying to update the data structure
concurrently will succeed in completing its operation within a bounded amount of
time, assuming that at least one process is active, regardless of the state of other
processes.
</code></pre>

<p>Lock-Free 的数据结构保证一个线程总能向前推进，避免了由于持有锁的线程被调度走而带来的开销。 Lock-Free 的数据结构一般需要用到特殊的指令,例如 xadd, Campare-And-Swap。这些指令保证原子地完成相应操作。</p>

<p>回到正文，我们现在来看一下如何实现 Lock-Free 的 Queue.
Queue需要保证先进先出<em>FIFO</em>的顺序，因此相比于List要简单一下。
我们要实现的Queue的两个例子。<img src="http://cnut-wp.github.com/images/queue-example.jpg" alt="queues" />
其中，对于空的Queue，head和tail均指向一个dummy node；对于有三个元素的Queue，head指向一个dummy node，而该dummy node指向Queue的第一个node，tail指向最后一个node。
enqueue过程稍微复杂一点，如图：<img src="http://cnut-wp.github.com/images/enqueue.jpg" alt="enqueue" />
这样的enqueue实现保证了数据链表始终是连续的，即使该enqueue被调度走，其他enqueue还是可以把tail移动到正确的位置正确。
dequeue则比较简单，只需要将相应的head向前一下就可以了。</p>

<p>具体代码：</p>

<pre><code>struct Node {
    int value;
    struct Node* next;
};


static inline
bool CAS(Node** mem, Node* old, Node* newVal)
{
    unsigned long r;
    __asm__ __volatile__("lock cmpxchgq %2,%1"
            : "=a" (r), "+m" (*mem)
            : "r" (newVal), "0" (old)
            : "memory");

    return r == (unsigned long)old ? 1 : 0;
}



Node * head=new Node;
Node * tail=head;

void enqueue(int x){
    Node* q = new Node;
    q-&gt;value = x;
    q-&gt;next = NULL;
    bool succ = false;
    Node *p;
    Node *next;
    do {
        p = tail;
        next = tail-&gt;next;
        if (p == tail) {
            if (next == NULL)
            {
                succ = CAS(&amp;(p-&gt;next), NULL, q);
            } else {
                CAS(&amp;tail,p,p-&gt;next);
            }
        }
    } while (!succ);
    CAS(&amp;tail,p,q);
    return;  
}

int dequeue(){
    Node *p; 
    Node *next;
    bool succ; 
    do{
        p = head;
        next = p-&gt;next;
        if (next == NULL){
            return -1;
        }
        succ = CAS(&amp;head, p, next);
        if (succ == true) {
            if (p == tail) {
                CAS(&amp;tail, tail, next);
            }
        } 
    }while(!succ);
    return p-&gt;next-&gt;value; 
}
</code></pre>

<p>该代码是在64位的Intel处理器上运行。</p>

<p>可以看出上面代码有一个很大的漏洞，就是<strong>没有释放内存</strong>。原因是这样的，因为Lock-Free的Queue要保证无论一个enqueue/dequeue的线程执行到哪里，都可以被调度走而不会导致其他线程阻塞。所以就会出现一种情况:一个dequeue的线程执行到一半的时候，被调度走；这时候其他dequeue的线程把前面线程要dequeue的node 移除了并将内存归还；这时如果前面的线程被调度上CPU，再去用它的之前读到的指针去访问相应内存，就会有问题。所以上面实现中没有释放内存。一个解决办法就是用提供GC的语言实现上面算法。</p>

<p>对于使用Compare-And-Swap原语的Lock-Free数据结构，都要考虑一个<strong>ABA</strong>问题。该个问题是这样的，Compare-And-Swap比较一个内存地址的值是不是还是用户提供的oldValue，如果是，就用用户提供的新的newVal去对该内存地址进行赋值。但是如果该内存地址的值是oldValue，该内存就一定是原来用户看到的状态吗？这是不一定的。有可能出现这种情况，该内存(head/tail)地址的值经过一系列dequeue/enqueue，值有回到了原来的oldValue，但是该oldValue和用户原来看到的oldValue有不同的含义（其他域可能不一样了）。这样就会造成一些问题。一个解决法案就是在扩展oldValue与newValue，使其包含一个递增的计数器。该计数器发生一次dequeue或者一次enqueue值就自增，这样就避免了前面的问题。不过这需要让Compare-And-Swap的位长变大。</p>

<p>性能测试：</p>

<table rules="all" cellpadding="15" border="1">
    <tr>
        <td></td>
        <td>enqueue</td>
        <td> en/de </td>
        <td>dequeue</td>
    </tr>
    <tr>
        <td>lock-free</td>
        <td>113106</td>
        <td>57256</td>
        <td>39831</td>
    </tr>
    <tr>
        <td>lock</td>
        <td>144583</td>
        <td>130820</td>
        <td>135425</td>
    </tr>
    <tr>
        <td></td>
    </tr>
</table>


<p>该测试是这样的，总共有10个线程，每个线程执行10000000操作（enqueue/dequeue）。enqueue列表示10个线程同时去enqueue，en/de表示各有5个线程去做enqueue和dequeue，而dequeue列表示10个线程同时去dequeue。物理机有16个core（Intel(R) Xeon(R) CPU E7310  @ 1.60GHz）。单位毫秒。</p>

<p>参考文档：</p>

<ul>
<li>Nonblocking Algorithms and Preemption-Safe Locking on Multiprogrammed Shared Memory Multiprocessors</li>
<li>Implememting Lock-Free Queues</li>
<li>Formal Verification of a Practical Lock-Free Queue Algorithm</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[all pull few push for git repo]]></title>
    <link href="http://cnut-wp.github.com/blog/2013/03/03/all-pull-few-push/"/>
    <updated>2013-03-03T20:40:00+08:00</updated>
    <id>http://cnut-wp.github.com/blog/2013/03/03/all-pull-few-push</id>
    <content type="html"><![CDATA[<p>这学期我担了一门课的助教。课上需要为学生建立一个 git 仓库。该仓库需要所有学生都有 pull 权限，但是又要赋予几个 TA push 权限。这个要求花了自己一段时间配置。</p>

<p>由于是低年级的学生，并且人数也比较多，所以复杂的授权认证不合适，最好学生什么都不需要做就可以 pull 代码。</p>

<p>git 支持许多协议，例如 http/https，git， ssh。http 可以很方便的让所有学生都能 pull 代码，但是却不能允许 TA push 代码 （或者我不知道如何配置），而 ssh 认证有很好的授权认证，但是它却比较烦。于是我选择了 git 协议。（以上分析来自 Pro Git）</p>

<p>首先，我用 gitolite 去管理所有 git 仓库。gitolite 操作十分地方便。具体参见 gitolite 官网。
需要注意的是，在使用 gitolite 配置仓库权限的时候可以这样写：</p>

<pre><code>repo    yourRepository
    RW+     =   TA
    R       =   daemon
</code></pre>

<p>这样 gitolite 会自动在仓库 yourRepository 中创建一个名字为 daemon-export-ok 的空文件，该文件会让 git daemon 把该仓库 share 出去。
然后再启动 git daemon。</p>

<pre><code>git daemon --reuseaddr --base-path=/example-repositories-dir-path /example-repositories-dir-path
</code></pre>

<p>之后就可以通过下面命令正常 clone 代码了。</p>

<pre><code>git clone git://your-server-name/yourRepository
</code></pre>

<p>说明：</p>

<ul>
<li>&#8211;reuseaddr 参数使得服务无须等到旧的连接尝试过期以后再重启，&#8211;base-path 参数使得 clone 项目的时候不用给出完整的路径，而最后面的路径告诉 Git  Daemon 进程需要导出仓库的位置。</li>
<li>确保启动 git daemon 的用户有读取仓库文件的权限。</li>
<li>可以在系统启动脚本中启动 daemon。</li>
</ul>


<p>参考文档：</p>

<ul>
<li>Pro Git</li>
<li><a href="http://gitolite.com/gitolite/qi.html">gitolite</a></li>
<li><a href="http://gitolite.com/gitolite/qi.html">http://gitolite.com/gitolite/qi.html</a></li>
<li><a href="http://granjow.net/git-read-access.html">http://granjow.net/git-read-access.html</a></li>
<li><a href="http://norbu09.org/2009/08/02/git-via-HTTP-(startup-automation-3).html">http://norbu09.org/2009/08/02/git-via-HTTP-(startup-automation-3).html</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hello world]]></title>
    <link href="http://cnut-wp.github.com/blog/2013/03/03/hello-world/"/>
    <updated>2013-03-03T18:43:00+08:00</updated>
    <id>http://cnut-wp.github.com/blog/2013/03/03/hello-world</id>
    <content type="html"><![CDATA[<p>A late come, but it is a start. And I hope it have a long life.</p>
]]></content>
  </entry>
  
</feed>
